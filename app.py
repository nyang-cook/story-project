import os
import openai
from audio_recorder_streamlit import audio_recorder
import streamlit as st
from gtts import gTTS
import base64


# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = openai.OpenAI(api_key="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")  # API í‚¤ ì…ë ¥


# ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (STT)
def STT(audio_data):
    filename = 'input.mp3'
    with open(filename, "wb") as f:
        f.write(audio_data)
    
    try:
        with open(filename, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="text"
            )
        transcript = response
    except Exception as e:
        transcript = f"STT ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    finally:
        if os.path.exists(filename):
            os.remove(filename)
    
    return transcript


# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (TTS)
def TTS(text):
    try:
        tts = gTTS(text, lang="ko")
        filename = "output.mp3"
        tts.save(filename)

        with open(filename, "rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode()
            md = f"""
                <audio autoplay="true" controls>
                <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
                </audio>
                """
            st.markdown(md, unsafe_allow_html=True)

        os.remove(filename)
    except Exception as e:
        st.error(f"TTS ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ChatGPTë¥¼ í™œìš©í•´ ë™í™” ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def ask_gpt(prompt):
    try:
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë™í™” ì‘ê°€ì•¼!, ì¥ë©´ë‹¹ 2-3ì¤„ì˜ ë™í™”ë¥¼ ì¨ì¤˜."},
                {"role": "user", "content": prompt}
            ],
            model="gpt-4o-mini"
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ChatGPT í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# DALL-Eë¥¼ í™œìš©í•´ ë™í™” ë‚´ìš©ì„ ê·¸ë¦¼ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_image(prompt):
    try:
        response = client.images.generate(
            model = "dall-e-2",
            prompt=prompt,
            n=1,
            size="512x512"  # ì›í•˜ëŠ” ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
        )
        image_url = response.data[0].url
        return image_url
    except Exception as e:
        return f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("AI ê¸°ë°˜ ë™í™” ìƒì„±ê¸° ğŸ¨ğŸ“–ğŸ¤")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "last_audio" not in st.session_state:
        st.session_state["last_audio"] = None

    st.header("ìŒì„± ì…ë ¥ ë°©ì‹ ì„ íƒ")
    input_mode = st.radio(
        "ìŒì„± ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
        ("ë…¹ìŒ", "íŒŒì¼ ì—…ë¡œë“œ")
    )

    if input_mode == "ë…¹ìŒ":
        st.subheader("ìŒì„± ë…¹ìŒ")
        audio_data = audio_recorder(text="ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ì„ ì…ë ¥í•˜ì„¸ìš”!")

        if audio_data:
            if audio_data != st.session_state["last_audio"]:
                st.session_state["last_audio"] = audio_data

                with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                    user_input = STT(audio_data)
                st.write(f"ğŸ¤ ë³€í™˜ëœ í…ìŠ¤íŠ¸: **{user_input}**")

                with st.spinner("ë™í™”ë¥¼ ìƒì„± ì¤‘..."):
                    story = ask_gpt(user_input)
                st.markdown(f"ğŸ“– ìƒì„±ëœ ë™í™”:\n\n{story}")

                with st.spinner("ë™í™”ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                    TTS(story)

                with st.spinner("ë™í™”ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                    image_url = generate_image(story)
                    if "ì˜¤ë¥˜ ë°œìƒ" not in image_url:
                        st.image(image_url, caption="DALL-Eê°€ ìƒì„±í•œ ë™í™” ì‚½í™”")
                    else:
                        st.error(image_url)
            else:
                st.info("ìƒˆë¡œìš´ ìŒì„±ì„ ë…¹ìŒí•´ì£¼ì„¸ìš”.")
        else:
            st.info("ìŒì„±ì„ ë…¹ìŒí•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    
    elif input_mode == "íŒŒì¼ ì—…ë¡œë“œ":
        st.subheader("ìŒì„± íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (MP3 í˜•ì‹)", type=["mp3"])

        if uploaded_file is not None:
            audio_data = uploaded_file.read()

            with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                user_input = STT(audio_data)
            st.write(f"ğŸ¤ ë³€í™˜ëœ í…ìŠ¤íŠ¸: **{user_input}**")

            with st.spinner("ë™í™”ë¥¼ ìƒì„± ì¤‘..."):
                story = ask_gpt(user_input)
            st.markdown(f"ğŸ“– ìƒì„±ëœ ë™í™”:\n\n{story}")

            with st.spinner("ë™í™”ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                TTS(story)

            with st.spinner("ë™í™”ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                image_url = generate_image(story)
                if "ì˜¤ë¥˜ ë°œìƒ" not in image_url:
                    st.image(image_url, caption="DALL-Eê°€ ìƒì„±í•œ ë™í™” ì‚½í™”")
                else:
                    st.error(image_url)


if __name__ == "__main__":
    main()